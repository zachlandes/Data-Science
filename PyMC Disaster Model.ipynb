{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://pymc-devs.github.io/pymc/tutorial.html\">PyMC Tutorial</a>\n",
    "<h3>The Model:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymc import DiscreteUniform, Exponential, deterministic, Poisson, Uniform\n",
    "import numpy as np\n",
    "\n",
    "disasters_array = \\\n",
    "        np.array([ 4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6,\n",
    "                   3, 3, 5, 4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5,\n",
    "                   2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 1, 1, 3, 0, 0,\n",
    "                   1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1,\n",
    "                   0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2,\n",
    "                   3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1, 4,\n",
    "                   0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])\n",
    "\n",
    "# switchpoint, all values equally likely a priori\n",
    "switchpoint = DiscreteUniform('switchpoint', lower=0, upper=110, doc='Switchpoint[year]')\n",
    "\n",
    "early_mean = Exponential('early_mean', beta=1.)\n",
    "late_mean = Exponential('late_mean', beta=1.)\n",
    "\n",
    "\"\"\"In PyMC terminology, the parameter rate is 'deterministic', meaning it's determined explicitly\n",
    "by observations of its parents. (It's still a random variable)\"\"\"\n",
    "@deterministic(plot=False)\n",
    "def rate(s=switchpoint, e=early_mean, l=late_mean):\n",
    "    # concatenate poisson means\n",
    "    out = np.empty(len(disasters_array)) # array of size 1 x len(disasters_array) with uninitialized values\n",
    "    out[:s] = e\n",
    "    out[s:] = l\n",
    "    return out                           # looks like [e, e, ..., e, l, l,...,l]\n",
    "\n",
    "\"\"\"Finally, we model the observed random variable, disasters. We have to assign it a probability distribution\n",
    "because we want to use Bayes' Theorem\"\"\"\n",
    "disasters = Poisson('disasters', mu=rate, value=disasters_array, observed=True) # note the declaration of observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 0, 'upper': 110}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import disaster_model\n",
    "disaster_model.switchpoint.parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mu': <pymc.PyMCObjects.Deterministic 'rate' at 0x1042cb090>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_model.disasters.parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<pymc.distributions.Poisson 'disasters' at 0x1042cb150>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_model.rate.children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that parents are dictionaries while children are sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6, 3, 3, 5, 4, 5, 3, 1,\n",
       "       4, 4, 1, 5, 5, 3, 4, 2, 5, 2, 2, 3, 4, 2, 1, 3, 2, 2, 1, 1, 1, 1, 3,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 3, 1, 0, 3, 2, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2, 3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 2,\n",
       "       0, 0, 1, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_model.disasters.value # we set this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(66)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_model.switchpoint.value # the following values were randomly assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.357683692267941)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_model.early_mean.value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.7417309029132656)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_model.late_mean.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  2.35768369,  2.35768369,  2.35768369,  2.35768369,\n",
       "        2.35768369,  0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,\n",
       "        0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,\n",
       "        0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,\n",
       "        0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,\n",
       "        0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,\n",
       "        0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,\n",
       "        0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,\n",
       "        0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,\n",
       "        0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,  0.7417309 ,\n",
       "        0.7417309 ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_model.rate.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><tt>logp</tt> returns the log of the probability density of a stochastic variable at their current values given the values\n",
    "of their parents. We can think of the -log probability as a scale of rarity, the larger the more rare.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.709530201312334"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_model.switchpoint.logp # log of uniform probability evaluated at switchpoint.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-185.07848122973684"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_model.disasters.logp # sum of logs of joint density for each element of disasters \n",
    "                              # given parents' (the parameters') values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.357683692267941"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_model.early_mean.logp # e~exp(1) so log(1*exp(-1*e)) = -e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7417309029132656"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_model.late_mean.logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00900900900900901"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import exp\n",
    "\n",
    "exp(disaster_model.switchpoint.logp) # because this came from a uniform(0,110) distribution it is == 1/111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-185.07848122973684"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"What logp is really doing for vector valued objects\"\"\"\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "arr = np.array([np.log(stats.poisson.pmf(disaster_model.disasters.value[i], mu=disaster_model.rate.value[i])) \n",
    "                for i in range(disaster_model.disasters.value.shape[0])])\n",
    "np.sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e': array(2.357683692267941), 'l': array(0.7417309029132656), 's': array(66)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_model.rate.parents.value # although these values are stochastic, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [-----------------100%-----------------] 10000 of 10000 complete in 2.1 sec"
     ]
    }
   ],
   "source": [
    "from pymc import MCMC\n",
    "\n",
    "#Markov Chain Monte Carlo Sampling\n",
    "M = MCMC(disaster_model)\n",
    "\n",
    "M.sample(iter=10000, burn=1000, thin=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>M.sample creates a series of retained samples of (<tt>s, e, l</tt>) from the posterior distribution of the model. <br>\n",
    "The MCMC joint distribution for <strong>P</strong>(<tt>s, e, l|D)</tt> converges to the true distribution, so we <tt>burn</tt> the <br>\n",
    "first 1000 values. Because the values are generated by a autoregressive stochastic process close by values <br>\n",
    "of the samples will be strongly autocorrelated so we take only every 10 values (<tt>thin=10</tt>)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
